{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":137,"status":"ok","timestamp":1710957431637,"user":{"displayName":"Lucas Cowden","userId":"00723183863400517056"},"user_tz":240},"id":"zaYtPQKMgFM7"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","from google.colab import drive"]},{"cell_type":"markdown","metadata":{"id":"ORD-yRr_iUGf"},"source":["Below, we retrieve the data and parse it using BeautifulSoup."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":844,"status":"ok","timestamp":1710957500688,"user":{"displayName":"Lucas Cowden","userId":"00723183863400517056"},"user_tz":240},"id":"nGTbYg5rgLiM"},"outputs":[],"source":["standings_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"\n","data = requests.get(standings_url)\n","soup = BeautifulSoup(data.text)"]},{"cell_type":"markdown","metadata":{"id":"XB3Kcjqhiedj"},"source":["Now, we want to retrieve the stats table, and retrieve the links associated with each Premier League team in the table."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xsqnB0zBhZSU"},"outputs":[],"source":["# We want the standings table, which is a table element with a class of 'stats_table'\n","# .select() will return a list of matching elements, but we want the first one, thus\n","# we index at 0\n","standings_table = soup.select('table.stats_table')[0]\n","# We use .find_all() because .select() uses CSS selectors, and .find() and .find_all()\n","# search just for tags. Could use either, but not necessary\n","links = standings_table.find_all('a')\n","# Want to get href property of each link. Use list comprehension to achieve this.\n","# NOTE: There are other links in the table we will need to filter out\n","links = [l.get(\"href\") for l in links]\n","# Filter out non-team links\n","links = [l for l in links if '/squads/' in l]\n","# Upon examining links, we can see that they only include the subdomains.\n","# Need to format links to include the main website domain.\n","team_urls = [f\"https://fbref.com{l}\" for l in links]"]},{"cell_type":"markdown","metadata":{"id":"gqlFP3Ysj2-d"},"source":["Scrape match statistics for each team"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HhH5xsGAhjAI"},"outputs":[],"source":["team_url = team_urls[0]\n","data = requests.get(team_url)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sp5AsghHhuMH"},"outputs":[],"source":["# Use pandas to turn the Scores & Fixtures table into a dataframe\n","matches = pd.read_html(data.text, match=\"Scores & Fixtures\")\n","#matches[0]"]},{"cell_type":"markdown","metadata":{"id":"0feiJk1WlJO0"},"source":["Get match shooting stats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L2u3zGxjlLYx"},"outputs":[],"source":["soup = BeautifulSoup(data.text)\n","links = soup.find_all('a')\n","links = [l.get(\"href\") for l in links]\n","links = [l for l in links if l and 'all_comps/shooting/' in l]\n","data = requests.get(f\"https://fbref.com{links[0]}\")\n","shooting = pd.read_html(data.text, match=\"Shooting\")[0]\n","#shooting.head()\n","# Need to drop first index level to remove the upper level of headers\n","shooting.columns = shooting.columns.droplevel()"]},{"cell_type":"markdown","metadata":{"id":"SxRjHn9MmxZV"},"source":["Merge the tables"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":154,"status":"ok","timestamp":1710883796919,"user":{"displayName":"Lucas Cowden","userId":"00723183863400517056"},"user_tz":240},"id":"B5M3HMEVm4EM","outputId":"4bc57e2c-f6dd-4406-effc-c87df6b109af"},"outputs":[{"data":{"text/plain":["(43, 25)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["team_data = matches[0].merge(shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on=\"Date\")\n","team_data.shape"]},{"cell_type":"markdown","metadata":{"id":"Nm79lmtxn12I"},"source":["Scrape from multiple teams and seasons"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":136,"status":"ok","timestamp":1710957509537,"user":{"displayName":"Lucas Cowden","userId":"00723183863400517056"},"user_tz":240},"id":"v6XKz6Vtn0MP"},"outputs":[],"source":["years = list(range(2023, 2018, -1))\n","#print(years)\n","all_matches = []\n","standings_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\""]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":675687,"status":"ok","timestamp":1710958187489,"user":{"displayName":"Lucas Cowden","userId":"00723183863400517056"},"user_tz":240},"id":"r_uHcDjiofFA","outputId":"6e8a5f7f-c006-4b22-f4cd-710a5c517220"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-7-4f532dc4bbfd>:31: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  team_data[\"Season\"] = year\n","<ipython-input-7-4f532dc4bbfd>:32: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  team_data[\"Team\"] = team_name\n","<ipython-input-7-4f532dc4bbfd>:31: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  team_data[\"Season\"] = year\n","<ipython-input-7-4f532dc4bbfd>:32: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  team_data[\"Team\"] = team_name\n","<ipython-input-7-4f532dc4bbfd>:31: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  team_data[\"Season\"] = year\n","<ipython-input-7-4f532dc4bbfd>:32: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  team_data[\"Team\"] = team_name\n","<ipython-input-7-4f532dc4bbfd>:31: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  team_data[\"Season\"] = year\n","<ipython-input-7-4f532dc4bbfd>:32: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  team_data[\"Team\"] = team_name\n"]}],"source":["for year in years:\n","  data = requests.get(standings_url)\n","  #print(data.text)\n","  soup = BeautifulSoup(data.text)\n","  standings_table = soup.select('table.stats_table')[0]\n","  links = [l.get(\"href\") for l in standings_table.find_all('a')]\n","  links = [l for l in links if '/squads/' in l]\n","  team_urls = [f\"https://fbref.com{l}\" for l in links]\n","\n","  previous_season = soup.select(\"a.prev\")[0].get(\"href\")\n","  standings_url = f\"https://fbref.com{previous_season}\"\n","  for team_url in team_urls:\n","    team_name = team_url.split('/')[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n","\n","    data = requests.get(team_url)\n","    matches = pd.read_html(data.text, match=\"Scores & Fixtures\")\n","\n","    soup = BeautifulSoup(data.text)\n","    links = [l.get(\"href\") for l in soup.find_all('a')]\n","    links = [l for l in links if l and 'all_comps/shooting/' in l]\n","    data = requests.get(f\"https://fbref.com{links[0]}\")\n","    shooting = pd.read_html(data.text, match=\"Shooting\")[0]\n","    shooting.columns = shooting.columns.droplevel()\n","\n","    try:\n","      team_data = matches[0].merge(shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on=\"Date\")\n","    except ValueError:\n","      continue\n","\n","    team_data = team_data[team_data[\"Comp\"] == \"Premier League\"]\n","    team_data[\"Season\"] = year\n","    team_data[\"Team\"] = team_name\n","    all_matches.append(team_data)\n","    time.sleep(4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M5WtzFoyq83-"},"outputs":[],"source":["match_df = pd.concat(all_matches)\n","#match_df\n","match_df.columns = [c.lower() for c in match_df.columns]\n","match_df"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":138,"status":"ok","timestamp":1710958403180,"user":{"displayName":"Lucas Cowden","userId":"00723183863400517056"},"user_tz":240},"id":"ssUUHI5kEDla"},"outputs":[],"source":["match_df.to_csv(\"matches.csv\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO97E1qhdBo/jPeTu0DOspa","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
